{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ETtu9CvVMDR"
   },
   "source": [
    "<h1>7ì¥ ê³ ê¸‰ í…ìŠ¤íŠ¸ ìƒì„± ê¸°ìˆ ê³¼ ë„êµ¬</h1>\n",
    "<i>í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì„ ë„˜ì–´ì„œ</i>\n",
    "\n",
    "<a href=\"https://github.com/rickiepark/handson-llm\"><img src=\"https://img.shields.io/badge/GitHub%20Repository-black?logo=github\"></a>\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rickiepark/handson-llm/blob/main/chapter07.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ <[í•¸ì¦ˆì˜¨ LLM](https://tensorflow.blog/handson-llm/)> ì±… 7ì¥ì˜ ì½”ë“œë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "<a href=\"https://tensorflow.blog/handson-llm/\">\n",
    "<img src=\"https://tensorflow.blog/wp-content/uploads/2025/05/ed95b8eca688ec98a8_llm.jpg\" width=\"350\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YtUx27GOCAYd"
   },
   "source": [
    "### [ì„ íƒì‚¬í•­] - <img src=\"https://colab.google/static/images/icons/colab.png\" width=100>ì—ì„œ íŒ¨í‚¤ì§€ ì„ íƒí•˜ê¸°\n",
    "\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì„ êµ¬ê¸€ ì½”ë©ì—ì„œ ì‹¤í–‰í•œë‹¤ë©´ ë‹¤ìŒ ì½”ë“œ ì…€ì„ ì‹¤í–‰í•˜ì—¬ ì´ ë…¸íŠ¸ë¶ì—ì„œ í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼  ì„¤ì¹˜í•˜ì„¸ìš”.\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ’¡ **NOTE**: ì´ ë…¸íŠ¸ë¶ì˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë ¤ë©´ GPUë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. êµ¬ê¸€ ì½”ë©ì—ì„œëŠ” **ëŸ°íƒ€ì„ > ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ > í•˜ë“œì›¨ì–´ ê°€ì†ê¸° > T4 GPU**ë¥¼ ì„ íƒí•˜ì„¸ìš”.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ê¹ƒí—ˆë¸Œì—ì„œ ìœ„ì ¯ ìƒíƒœ ì˜¤ë¥˜ë¥¼ í”¼í•˜ê¸° ìœ„í•´ ì§„í–‰ í‘œì‹œì¤„ì„ ë‚˜íƒ€ë‚´ì§€ ì•Šë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "import os\n",
    "import tqdm\n",
    "from transformers.utils import logging\n",
    "\n",
    "# tqdm ë¹„í™œì„±í™”\n",
    "tqdm.tqdm = lambda *args, **kwargs: iter([])\n",
    "tqdm.auto.tqdm = lambda *args, **kwargs: iter([])\n",
    "tqdm.notebook.tqdm = lambda *args, **kwargs: iter([])\n",
    "os.environ[\"DISABLE_TQDM\"] = \"1\"\n",
    "\n",
    "logging.disable_progress_bar()"
   ],
   "metadata": {
    "id": "ILBN7AMQ0SfM"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Txh47zAxCAYd"
   },
   "source": [
    "%%capture\n",
    "!pip install langchain_community langchain_openai duckduckgo-search\n",
    "\n",
    "# ì‚¬ìš©í•˜ëŠ” íŒŒì´ì¬ê³¼ CUDA ë²„ì „ì— ë§ëŠ” llama-cpp-python íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”.\n",
    "# í˜„ì¬ ì½”ë©ì˜ íŒŒì´ì¬ ë²„ì „ì€ 3.11ì´ë©° CUDA ë²„ì „ì€ 12.4ì…ë‹ˆë‹¤.\n",
    "!pip install https://github.com/abetlen/llama-cpp-python/releases/download/v0.3.4-cu124/llama_cpp_python-0.3.4-cp311-cp311-linux_x86_64.whl"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rerbJgwAigbK"
   },
   "source": [
    "# LLM ë¡œë“œí•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4EYKJi4bCAYf",
    "outputId": "2fb3d05c-bb34-4214-c909-2c903dab1469"
   },
   "source": [
    "!wget https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-fp16.gguf"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LQcht_ZFijW7",
    "outputId": "79746405-eff5-477c-8b97-edbf21a61005"
   },
   "source": [
    "from langchain import LlamaCpp\n",
    "\n",
    "# ì—¬ëŸ¬ë¶„ì˜ ì»´í“¨í„°ì— ë‹¤ìš´ë¡œë“œí•œ ëª¨ë¸ì˜ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”!\n",
    "llm = LlamaCpp(\n",
    "    model_path=\"Phi-3-mini-4k-instruct-fp16.gguf\",\n",
    "    n_gpu_layers=-1,\n",
    "    max_tokens=500,\n",
    "    n_ctx=4096,\n",
    "    seed=42,\n",
    "    verbose=False\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "3SNhQF9WthzV",
    "outputId": "fb7b2b19-ac91-4308-bc3b-586769ea928c"
   },
   "source": [
    "llm.invoke(\"Hi! My name is Maarten. What is 1 + 1?\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wwx2AIuGfCoP"
   },
   "source": [
    "## ì²´ì¸"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kF--Q5me_-X1"
   },
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "# \"input_prompt\" ë³€ìˆ˜ë¥¼ ê°€ì§„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "template = \"\"\"<|user|>\n",
    "{input_prompt}<|end|>\n",
    "<|assistant|>\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"input_prompt\"]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ogWsGeg6hElt"
   },
   "source": [
    "basic_chain = prompt | llm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "KINQxKAINXgG",
    "outputId": "db64b3e1-d0cc-42c3-8c9e-5683f1140e32"
   },
   "source": [
    "# ì²´ì¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "basic_chain.invoke(\n",
    "    {\n",
    "        \"input_prompt\": \"Hi! My name is Maarten. What is 1 + 1?\",\n",
    "    }\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSMBMRxB8gFW"
   },
   "source": [
    "### ì—¬ëŸ¬ í…œí”Œë¦¿ì„ ê°€ì§„ ì²´ì¸"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wrUKuHt_OLpe",
    "outputId": "b65545de-9bce-4970-c622-0befcb4ef8c1"
   },
   "source": [
    "from langchain import LLMChain\n",
    "\n",
    "# ì´ì•¼ê¸° ì œëª©ì„ ìœ„í•œ ì²´ì¸ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "template = \"\"\"<|user|>\n",
    "Create a title for a story about {summary}. Only return the title.<|end|>\n",
    "<|assistant|>\"\"\"\n",
    "title_prompt = PromptTemplate(template=template, input_variables=[\"summary\"])\n",
    "title = LLMChain(llm=llm, prompt=title_prompt, output_key=\"title\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "igFIyg73OtaL",
    "outputId": "2a7113da-fb93-4b70-8703-347b09d51230"
   },
   "source": [
    "title.invoke({\"summary\": \"a girl that lost her mother\"})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zTtFEmANOhyE"
   },
   "source": [
    "# ìš”ì•½ê³¼ ì œëª©ì„ ì‚¬ìš©í•˜ì—¬ ìºë¦­í„° ì„¤ëª…ì„ ìƒì„±í•˜ëŠ” ì²´ì¸ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "template = \"\"\"<|user|>\n",
    "Describe the main character of a story about {summary} with the title {title}.\n",
    "Use only two sentences.<|end|>\n",
    "<|assistant|>\"\"\"\n",
    "character_prompt = PromptTemplate(\n",
    "    template=template, input_variables=[\"summary\", \"title\"]\n",
    ")\n",
    "character = LLMChain(llm=llm, prompt=character_prompt, output_key=\"character\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Xjf-avW8NAqZ"
   },
   "source": [
    "# ìš”ì•½, ì œëª©, ìºë¦­í„° ì„¤ëª…ì„ ì‚¬ìš©í•´ ì´ì•¼ê¸°ë¥¼ ìƒì„±í•˜ëŠ” ì²´ì¸ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "template = \"\"\"<|user|>\n",
    "Create a story about {summary} with the title {title}.\n",
    "The main charachter is: {character}.\n",
    "Only return the story and it cannot be longer than one paragraph<|end|>\n",
    "<|assistant|>\"\"\"\n",
    "story_prompt = PromptTemplate(\n",
    "    template=template, input_variables=[\"summary\", \"title\", \"character\"]\n",
    ")\n",
    "story = LLMChain(llm=llm, prompt=story_prompt, output_key=\"story\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "epNudKyyPClO"
   },
   "source": [
    "# ì„¸ ê°œì˜ ìš”ì†Œë¥¼ ì—°ê²°í•˜ì—¬ ìµœì¢… ì²´ì¸ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "llm_chain = title | character | story"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b44ZR0vXRaAo",
    "outputId": "b9751173-1dcf-431f-b43a-7659013a6aae"
   },
   "source": [
    "llm_chain.invoke(\"a girl that lost her mother\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UQ-DZ71P-D-"
   },
   "source": [
    "# ë©”ëª¨ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "-15Eoey5EJUO",
    "outputId": "3eda9bf7-31d1-4215-a7a8-2cce34721fa1"
   },
   "source": [
    "# LLMì—ê²Œ ì´ë¦„ì„ ì•Œë ¤ ì¤ë‹ˆë‹¤.\n",
    "basic_chain.invoke({\"input_prompt\": \"Hi! My name is Maarten. What is 1 + 1?\"})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "N42wQRl-Lykt",
    "outputId": "c399add1-e309-417e-c225-0f51aa754719"
   },
   "source": [
    "# LLMì—ê²Œ ì´ë¦„ì„ ë¬»ìŠµë‹ˆë‹¤.\n",
    "basic_chain.invoke({\"input_prompt\": \"What is my name?\"})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PfqATEZjMgET"
   },
   "source": [
    "### ëŒ€í™” ë²„í¼"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Zoo0PA1fUs70"
   },
   "source": [
    "# ëŒ€í™” ê¸°ë¡ì„ ë‹´ì„ ìˆ˜ ìˆë„ë¡ í”„ë¡¬í”„íŠ¸ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n",
    "template = \"\"\"<|user|>Current conversation:{chat_history}\n",
    "\n",
    "{input_prompt}<|end|>\n",
    "<|assistant|>\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"input_prompt\", \"chat_history\"]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bgGMS1S9saLi",
    "outputId": "facd6321-09eb-405f-d53f-4bb8ff6f1662"
   },
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# ì‚¬ìš©í•  ë©”ëª¨ë¦¬ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "# LLM, í”„ë¡¬í”„íŠ¸, ë©”ëª¨ë¦¬ë¥¼ ì—°ê²°í•©ë‹ˆë‹¤.\n",
    "llm_chain = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=llm,\n",
    "    memory=memory\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mltR_GtkiqDZ",
    "outputId": "f75bb690-1275-4525-c26d-079ada5b6831"
   },
   "source": [
    "# ê°„ë‹¨í•œ ì§ˆë¬¸ì„ í•˜ì—¬ ëŒ€í™” ê¸°ë¡ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "llm_chain.invoke({\"input_prompt\": \"Hi! My name is Maarten. What is 1 + 1?\"})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-je1rmy3dx4",
    "outputId": "231fafa4-c233-4ead-f50f-0fe4f99e5aca"
   },
   "source": [
    "# LLMì´ ì´ë¦„ì„ ê¸°ì–µí• ê¹Œìš”?\n",
    "llm_chain.invoke({\"input_prompt\": \"What is my name?\"})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sw3ELCg6Rpsk"
   },
   "source": [
    "### ìœˆë„ ëŒ€í™” ë²„í¼"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G0DRT7kjRtiC",
    "outputId": "ea324a12-46a8-4585-f472-557b7e58ba9b"
   },
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "# ë©”ëª¨ë¦¬ì— ë§ˆì§€ë§‰ ë‘ ê°œì˜ ëŒ€í™”ë§Œ ìœ ì§€í•©ë‹ˆë‹¤.\n",
    "memory = ConversationBufferWindowMemory(k=2, memory_key=\"chat_history\")\n",
    "\n",
    "# LLM, í”„ë¡¬í”„íŠ¸, ë©”ëª¨ë¦¬ë¥¼ ì—°ê²°í•©ë‹ˆë‹¤.\n",
    "llm_chain = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=llm,\n",
    "    memory=memory\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CBY69vvcR1Qq",
    "outputId": "f1090de7-d296-49c9-f19b-64242c1b5fc3"
   },
   "source": [
    "# ë‘ ê°œì˜ ì§ˆë¬¸ì„ ë˜ì ¸ ë©”ëª¨ë¦¬ì— ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "llm_chain.invoke({\"input_prompt\":\"Hi! My name is Maarten and I am 33 years old. What is 1 + 1?\"})\n",
    "llm_chain.invoke({\"input_prompt\":\"What is 3 + 3?\"})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nvSLfKWpR5h5",
    "outputId": "6845c17e-384b-495e-ebb9-0a6699ea74ed"
   },
   "source": [
    "# ì´ë¦„ì„ ê¸°ì–µí•˜ëŠ”ê³  ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "llm_chain.invoke({\"input_prompt\":\"What is my name?\"})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YW7qEyctcqeJ",
    "outputId": "a5b398bc-c5ff-4001-8ec2-1eff34eac85d"
   },
   "source": [
    "# ì´ë¦„ì„ ê¸°ì–µí•˜ëŠ”ê³  ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "llm_chain.invoke({\"input_prompt\":\"What is my age?\"})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSb5OnANMhu2"
   },
   "source": [
    "### ëŒ€í™” ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lWHZlJUbwpqE"
   },
   "source": [
    "# ìš”ì•½ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "summary_prompt_template = \"\"\"<|user|>Summarize the conversations and update with the new lines.\n",
    "\n",
    "Current summary:\n",
    "{summary}\n",
    "\n",
    "new lines of conversation:\n",
    "{new_lines}\n",
    "\n",
    "New summary:<|end|>\n",
    "<|assistant|>\"\"\"\n",
    "summary_prompt = PromptTemplate(\n",
    "    input_variables=[\"new_lines\", \"summary\"],\n",
    "    template=summary_prompt_template\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qg1HAgxZMkbO",
    "outputId": "61d85942-dee1-4511-f6c2-0c6f5fd2d410"
   },
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "# ì‚¬ìš©í•  ë©”ëª¨ë¦¬ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "memory = ConversationSummaryMemory(\n",
    "    llm=llm,\n",
    "    memory_key=\"chat_history\",\n",
    "    prompt=summary_prompt\n",
    ")\n",
    "\n",
    "# LLM, í”„ë¡¬í”„íŠ¸, ë©”ëª¨ë¦¬ë¥¼ ì—°ê²°í•©ë‹ˆë‹¤.\n",
    "llm_chain = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=llm,\n",
    "    memory=memory\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2klIk9CpVSH0",
    "outputId": "37b45670-5f41-445f-ca9f-ec042b6f2494"
   },
   "source": [
    "# ì´ë¦„ì— ëŒ€í•´ ì§ˆë¬¸í•˜ëŠ” ëŒ€í™”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "llm_chain.invoke({\"input_prompt\": \"Hi! My name is Maarten. What is 1 + 1?\"})\n",
    "llm_chain.invoke({\"input_prompt\": \"What is my name?\"})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_VdOH_I-V-Fy",
    "outputId": "de109966-6cfe-4807-f935-81d3351b9376"
   },
   "source": [
    "# ì§€ê¸ˆê¹Œì§€ ë‚´ìš©ì´ ìš”ì•½ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "llm_chain.invoke({\"input_prompt\": \"What was the first question I asked?\"})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n1_LlvrVX9HL",
    "outputId": "6b5d365d-5859-4587-fe81-762a8ed66416"
   },
   "source": [
    "# ì§€ê¸ˆê¹Œì§€ ìš”ì•½ ë‚´ìš©ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "memory.load_memory_variables({})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BG5sJa1qvS4N"
   },
   "source": [
    "# ì—ì´ì „íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rcBt8bZM56dM"
   },
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ë­ì²´ì¸ìœ¼ë¡œ ì˜¤í”ˆAIì˜ LLMì„ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"MY_KEY\"\n",
    "openai_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lmRZu8DO2p6k"
   },
   "source": [
    "# ReAct í…œí”Œë¦¿ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "react_template = \"\"\"Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=react_template,\n",
    "    input_variables=[\"tools\", \"tool_names\", \"input\", \"agent_scratchpad\"]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NV-ssNa-4zOK"
   },
   "source": [
    "from langchain.agents import load_tools, Tool\n",
    "from langchain.tools import DuckDuckGoSearchResults\n",
    "\n",
    "# ì—ì´ì „íŠ¸ì— ì „ë‹¬í•  ë„êµ¬ë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
    "search = DuckDuckGoSearchResults()\n",
    "search_tool = Tool(\n",
    "    name=\"duckduck\",\n",
    "    description=\"A web search engine. Use this to as a search engine for general queries.\",\n",
    "    func=search.run,\n",
    ")\n",
    "\n",
    "# ë„êµ¬ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
    "tools = load_tools([\"llm-math\"], llm=openai_llm)\n",
    "tools.append(search_tool)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6tAr1962vS4T"
   },
   "source": [
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "\n",
    "# ReAct ì—ì´ì „íŠ¸ë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
    "agent = create_react_agent(openai_llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, tools=tools, verbose=True, handle_parsing_errors=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QSU6ECdYBOOm",
    "outputId": "44c7607a-4f45-4b45-810a-547a6632a712"
   },
   "source": [
    "# ë§¥ë¶ í”„ë¡œì˜ ê°€ê²©ì€ ì–¼ë§ˆì¸ê°€ìš”?\n",
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"What is the current price of a MacBook Pro in USD? How much would it cost in EUR if the exchange rate is 0.85 EUR for 1 USD?\"\n",
    "    }\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
