{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_a9QvUFVCUR"
   },
   "source": [
    "<h1>4장 텍스트 분류</h1>\n",
    "<i>표현 모델과 생성 모델을 사용해 텍스트 분류하기</i>\n",
    "\n",
    "<a href=\"https://github.com/rickiepark/handson-llm\"><img src=\"https://img.shields.io/badge/GitHub%20Repository-black?logo=github\"></a>\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rickiepark/handson-llm/blob/main/chapter04.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "이 노트북은 <[핸즈온 LLM](https://tensorflow.blog/handson-llm/)> 책 4장의 코드를 담고 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "<a href=\"https://tensorflow.blog/handson-llm/\">\n",
    "<img src=\"https://tensorflow.blog/wp-content/uploads/2025/05/ed95b8eca688ec98a8_llm.jpg\" width=\"350\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkgx7Ubhy0SL"
   },
   "source": [
    "### [선택사항] - <img src=\"https://colab.google/static/images/icons/colab.png\" width=100>에서 패키지 선택하기\n",
    "\n",
    "\n",
    "이 노트북을 구글 코랩에서 실행한다면 다음 코드 셀을 실행하여 이 노트북에서 필요한 패키지를  설치하세요.\n",
    "\n",
    "---\n",
    "\n",
    "💡 **NOTE**: 이 노트북의 코드를 실행하려면 GPU를 사용하는 것이 좋습니다. 구글 코랩에서는 **런타임 > 런타임 유형 변경 > 하드웨어 가속기 > T4 GPU**를 선택하세요.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yvWiFESCy0SN"
   },
   "source": [
    "%%capture\n",
    "!pip install datasets"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "05VEeiVN2Aqk"
   },
   "source": [
    "# 깃허브에서 위젯 상태 오류를 피하기 위해 진행 표시줄을 나타내지 않도록 설정합니다.\n",
    "from transformers.utils import logging\n",
    "\n",
    "logging.disable_progress_bar()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBeVnXxQWy7-"
   },
   "source": [
    "# 영화 리뷰 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380,
     "referenced_widgets": [
      "14d51a7529d24d9a9e2464d8cf9dfdc2",
      "40710dac0b6b43fe95401c39e39dd18b",
      "4596c47561024d28a186aa366671f5a8",
      "ccc0588e017248249721a52af90d63ab",
      "8537fce8d1514ee1b0a76f15803bbd03",
      "497cd66ab8634679aa9368b4ba33c2a8",
      "6d00f8758edf4e30804cfb21b1689239",
      "d817090b1a5c4bd4a957b3c6917419f2",
      "93962719338f46d0a3a3fe6f3aeb4551",
      "8a698b9cc77e4ca698489c834553be6b",
      "a0c9fc9779ea44adbb9cc0aac5fbbd06",
      "022ca29c9167402f9b3819b4ef47d5ab",
      "00a979641bdf4e5283a84501f29dcbea",
      "ecc0612290234a86834db84501ae9d45",
      "11ff4a6387ed492d9f1fe4afecabb050",
      "a899280b0a584a9eae2675945f30d917",
      "501a179122d0465d8236ac33e34ee869",
      "5dd4c56d2652403990d942e7d6453265",
      "6f890a7efadd46eda007921686f60204",
      "9e828de3f5724b508f32bb4b5ec7aa8a",
      "6cc46c0921f749aa90ea63811349bfea",
      "fd1c35212ba9489fa6601540943f1354",
      "34dbad5441fd444b9439ff01caf0048a",
      "75f713a1f6dc4f2e90a918967edcba81",
      "21bcdc9290c44b97a58aa2ce04384f3b",
      "382555a14b754e29bb159c308dd0f90e",
      "5c908713a62e4bb7a301e9a37d0250e3",
      "f8802ab3eaa24ae295c0d858eae29e04",
      "ec39bdad8a3240578759953de9393172",
      "37db9853f3c24c06a61477614fabb61d",
      "5caad4a596214b88af4513a4d1f3227d",
      "3391ae3388a44b82a727f072b5d396f4",
      "c90d80fed7dd45d194e372ea4f839486"
     ]
    },
    "id": "5phRS_z2U_3T",
    "outputId": "68580bd1-2680-4d17-d81f-77aaa3f6448d"
   },
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 데이터를 로드합니다.\n",
    "data = load_dataset(\"rotten_tomatoes\")\n",
    "data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xJJmaJzHDLZv",
    "outputId": "4ca51e68-585e-48c8-949e-3414ad43ed51"
   },
   "source": [
    "data[\"train\"][0, -1]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xya5dfmVoR1R"
   },
   "source": [
    "# 표현 모델로 텍스트 분류하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "co68g-Eloknf"
   },
   "source": [
    "# 작업에 특화된 모델 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ph-3T3XJopdN",
    "outputId": "942f8c3e-efde-4b31-9f9a-6e76a64f7390"
   },
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 허깅 페이스 모델 경로\n",
    "model_path = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "# 파이프라인으로 모델을 로드합니다.\n",
    "pipe = pipeline(\n",
    "    model=model_path,\n",
    "    tokenizer=model_path,\n",
    "    return_all_scores=True,\n",
    "    device=\"cuda:0\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B2gbnL5Q69Y5",
    "outputId": "43c6ee42-8601-4b0f-8333-9ffb7871cc45"
   },
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "\n",
    "# 추론을 실행합니다.\n",
    "y_pred = []\n",
    "for output in tqdm(pipe(KeyDataset(data[\"test\"], \"text\")), total=len(data[\"test\"])):\n",
    "    negative_score = output[0][\"score\"]\n",
    "    positive_score = output[2][\"score\"]\n",
    "    assignment = np.argmax([negative_score, positive_score])\n",
    "    y_pred.append(assignment)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "X0KyKHtqyjn3"
   },
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate_performance(y_true, y_pred):\n",
    "    \"\"\"분류 리포트를 만들어 출력합니다.\"\"\"\n",
    "    performance = classification_report(\n",
    "        y_true, y_pred,\n",
    "        target_names=[\"Negative Review\", \"Positive Review\"]\n",
    "    )\n",
    "    print(performance)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fum3MTSyymlW",
    "outputId": "dc670b49-829f-4556-a41d-5463bdf84b60"
   },
   "source": [
    "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wr3WT4jzoNZE"
   },
   "source": [
    "# 임베딩을 활용하여 분류 작업 수행하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8yuSP3heMzT"
   },
   "source": [
    "## 지도 학습 분류"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "f686b390da4d4f3dbacfe6ef8f7bcd8f",
      "76ed8450c33e44e298eb840c60606dc5",
      "0b76c6deb50a4878a69ebc2b5e7ced47",
      "04b994867d8e4b95a026c4ffb6020802",
      "c1989d202ff1447c88c8552e86693fc5",
      "178866b7a543481996e83e9b0b12b866",
      "a95a3081aeb443c1b0fa026854bb7990",
      "babc0b84777f4476ae88a04ea866684c",
      "20416550415d4c84b350b1fbed8439b3",
      "6ef7d4d70031483e880fee9c1e940b24",
      "2fb73017d87043a0980466533243303f",
      "c6cbea5d99c54917a33298434138532d",
      "333de70e43974b53b7c31a4bdc22a1bf",
      "7d9d6b68370d456fad943f15849e6522",
      "75a6d19369884d83b1dcc8e1c609aa8d",
      "d10cbd3d38a64398845e1c8f68b9a9ad",
      "b0665e74565a41489a58cff0c7113ea2",
      "80c544c90ef548158bb91e15cf6fb40d",
      "5dd5804729f34614878d55e3a2db6df4",
      "86de157bdaf84b91b16cc9b98f968226",
      "342d464ddc0e40c285983a05642d4edc",
      "edf72147cc234725839e03014b5caa3c"
     ]
    },
    "id": "jGV9VS4bhq7f",
    "outputId": "3201e814-b831-446d-ca01-6c518d41724c"
   },
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 모델을 로드합니다.\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# 텍스트를 임베딩으로 변환합니다.\n",
    "train_embeddings = model.encode(list(data[\"train\"][\"text\"]), show_progress_bar=True)\n",
    "test_embeddings = model.encode(list(data[\"test\"][\"text\"]), show_progress_bar=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B5L5CLcOxIeA",
    "outputId": "4e0fb65c-317f-4aa1-a0cb-4b00a03ea410"
   },
   "source": [
    "train_embeddings.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "id": "8A7oTxoph6bn",
    "outputId": "87cc967f-e871-4f13-ae0e-797e3c56523d"
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 훈련 세트의 임베딩으로 로지스틱 회귀 모델을 훈련합니다.\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(train_embeddings, data[\"train\"][\"label\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tFvO9KhMokF7",
    "outputId": "833e3da5-5d35-4075-9858-3411c2700114"
   },
   "source": [
    "# 테스트 세트 임베딩에 대해 예측을 수행합니다.\n",
    "y_pred = clf.predict(test_embeddings)\n",
    "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwGIHxXpJgrC"
   },
   "source": [
    "**팁!**  \n",
    "\n",
    "분류기를 사용하지 않는다면 어떻게 할 수 있을까요? 분류기 대신 클래스별 임베딩을 평균하고 코사인 유사도를 적용하여 문서와 가장 잘 맞는 클래스를 예측할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3f_DnG1uJ7Sk",
    "outputId": "3daec7a3-f253-4156-c5b5-280066875b3d"
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 타깃 레이블에 대한 문서의 임베딩을 모두 평균하여 타깃 임베딩을 만듭니다.\n",
    "df = pd.DataFrame(np.hstack([train_embeddings, np.array(data[\"train\"][\"label\"]).reshape(-1, 1)]))\n",
    "averaged_target_embeddings = df.groupby(768).mean().values\n",
    "\n",
    "# 테스트 임베딩과 가장 가까운 타깃 임베딩을 찾습니다.\n",
    "sim_matrix = cosine_similarity(test_embeddings, averaged_target_embeddings)\n",
    "y_pred = np.argmax(sim_matrix, axis=1)\n",
    "\n",
    "# 모델을 평가합니다.\n",
    "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCWdzjMIjzx0"
   },
   "source": [
    "## 데이터에 레이블이 없는 경우"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YSj6CdAetsNp"
   },
   "source": [
    "# 레이블의 임베딩을 만듭니다.\n",
    "label_embeddings = model.encode([\"A negative review\",  \"A positive review\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZEIN7XnbtsQJ"
   },
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 각 문서와 가장 잘 맞는 레이블을 찾습니다.\n",
    "sim_matrix = cosine_similarity(test_embeddings, label_embeddings)\n",
    "y_pred = np.argmax(sim_matrix, axis=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u6LyeuEUxIbW",
    "outputId": "eb7f90ce-5bb3-4e61-83d6-5c2309a71259"
   },
   "source": [
    "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ox27Rg71zclg"
   },
   "source": [
    "**팁!**  \n",
    "\n",
    "설명을 다르게 하면 어떨까요? **\"A very negative movie review\"**와 **\"A very positive movie review\"**를 사용하면 어떻게 되는지 확인해 보세요!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1OwdMqDnzuJ3",
    "outputId": "6cc0c3b5-503b-4290-d282-21184679dceb"
   },
   "source": [
    "label_embeddings = model.encode([\"A very negative movie review\",\n",
    "                                 \"A very positive movie review\"])\n",
    "\n",
    "sim_matrix = cosine_similarity(test_embeddings, label_embeddings)\n",
    "y_pred = np.argmax(sim_matrix, axis=1)\n",
    "\n",
    "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4CC9iEGcuUit"
   },
   "source": [
    "# 생성 모델로 텍스트 분류하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFPPzUHoEESB"
   },
   "source": [
    "## T5 모델 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nVbTUMktEfJ3",
    "outputId": "434cf89c-5150-4346-e25d-51ba2f8f9284"
   },
   "source": [
    "# 모델을 로드합니다.\n",
    "pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"google/flan-t5-small\",\n",
    "    device=\"cuda:0\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380,
     "referenced_widgets": [
      "c08470d265234c59846538c597c53b32",
      "344ef857506448619d0855cbb249f1c1",
      "c8de79397eb849d09a6c76524139829f",
      "49ce7d4ae5e14811b533456f38e0d7db",
      "111e9c4b257b4c9cabe15501bea4680f",
      "96c023f2b3a243b0a3bb3f0b3dbb4056",
      "42d917e89b5d4c62a27a3b30c958596e",
      "4bff1b540a2546c0a7a3009e54505459",
      "e3a8fabd09714ee9bf998ecca3d51bbe",
      "9e2482e7d424413c8400d1d55b88d7e3",
      "c1822ac35e88472e821ff16a1565e208",
      "9640674f99824bdcb09bbd0ac8c83a77",
      "4910e66f9c2748cfb1e3c0ef436c9a08",
      "4dfb4be73a164698bcdd036f226bd9d5",
      "400b16c1596747ea9cca1581376549ef",
      "b2ea6fc624f54249ba30158138432028",
      "6845eed13d0f47b28a8f4bcf59334cde",
      "7efa9bfa63fe4d9d8eccd50b5a2e1925",
      "7a13dea67d064527b425f6dfce89900b",
      "c4086455134e4bd386dc946747a2188e",
      "ce8e297c977b4323b0ac5c39ade36334",
      "24b5f80094d040ed905bf15b5cacd7c3",
      "7dce094156494bb18d0e3d8c317ed3aa",
      "b7017b4ff0aa4a85a582b692bb1be64a",
      "1899c7867b29466bbb1a4ecbe404b038",
      "83adb8caa2154c4c91e267bf73aed80f",
      "3543dc2758474dec9cdb31c7442d9f13",
      "9d91b52b890845098eb48aa446ddeb85",
      "29f105dcc17a4cb082afb181c0d78e02",
      "322d3bc9de35427b839e9233ebd247e9",
      "6479191a926741959a87bccda5d1620e",
      "646df3690ab04480a955a2ca30e9931e",
      "5bba95469825463a93c23ed7a0f659d5"
     ]
    },
    "id": "o5nWQORcFlNn",
    "outputId": "f2f64154-2a7c-4000-aaf1-fbc00b88000f"
   },
   "source": [
    "# 프롬프트를 추가합니다.\n",
    "prompt = \"Is the following sentence positive or negative? \"\n",
    "data = data.map(lambda example: {\"t5\": prompt + example['text']})\n",
    "data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nas574KFFSvR",
    "outputId": "a0988f65-f0c4-46da-9ec7-20213697ad4b"
   },
   "source": [
    "# 추론을 실행합니다.\n",
    "y_pred = []\n",
    "for output in tqdm(pipe(KeyDataset(data[\"test\"], \"t5\")), total=len(data[\"test\"])):\n",
    "    text = output[0][\"generated_text\"]\n",
    "    y_pred.append(0 if text == \"negative\" else 1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Wk2i856GnCv",
    "outputId": "1f61f813-13d8-4645-8631-b06da439dd01"
   },
   "source": [
    "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4V9iq_EELWx"
   },
   "source": [
    "## ChatGPT로 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fJU5_X573XIT",
    "outputId": "408168d4-4be5-4bd5-cafa-0d2e73fc4a86"
   },
   "source": [
    "# httpx 패키지의 proxies 매개변수 오류를 피하기 위해\n",
    "# https://community.openai.com/t/error-with-openai-1-56-0-client-init-got-an-unexpected-keyword-argument-proxies/\n",
    "!pip install openai==1.55.3 httpx==0.27.2 --force-reinstall --quiet"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tES6HFOwNjF6"
   },
   "source": [
    "import openai\n",
    "\n",
    "# 클라이언트를 만듭니다.\n",
    "client = openai.OpenAI(api_key=\"YOUR_KEY_HERE\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dGiovm3wyCOz"
   },
   "source": [
    "def chatgpt_generation(prompt, document, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"프롬프트와 문서를 입력받아 출력을 생성합니다.\"\"\"\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\"\n",
    "            },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\":   prompt.replace(\"[DOCUMENT]\", document)\n",
    "            }\n",
    "    ]\n",
    "    chat_completion = client.chat.completions.create(\n",
    "      messages=messages,\n",
    "      model=model,\n",
    "      temperature=0\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "qL_kMwQEvMcd",
    "outputId": "866a4be1-948d-45d3-a52a-2a73386c4591"
   },
   "source": [
    "# 프롬프트 템플릿을 정의합니다.\n",
    "prompt = \"\"\"Predict whether the following document is a positive or negative movie review:\n",
    "\n",
    "[DOCUMENT]\n",
    "\n",
    "If it is positive return 1 and if it is negative return 0. Do not give any other answers.\n",
    "\"\"\"\n",
    "\n",
    "# Predict the target using GPT\n",
    "document = \"unpretentious , charming , quirky , original\"\n",
    "chatgpt_generation(prompt, document)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ea-8XYpY3jp6"
   },
   "source": [
    "다음 단계는 전체 테스트 데이터로 오픈AI 모델 중 하나를 실행하는 것입니다. 하지만 전체 테스트 데이터는 1,066개이므로 충분한 크레딧이 있을 때만 실행하세요."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gEyGElIv25Aq",
    "outputId": "a9f68279-0bda-41d1-91fc-9f4937ff7d1c"
   },
   "source": [
    "# 무료 크레딧을 아끼고 싶다면 이 코드를 건너 뛰세요.\n",
    "predictions = [chatgpt_generation(prompt, doc) for doc in tqdm(data[\"test\"][\"text\"])]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B07O8wtZ05x1",
    "outputId": "46282aed-ea18-4e88-dc94-cedb8faa404e"
   },
   "source": [
    "# 예측을 저장합니다.\n",
    "y_pred = [int(pred) for pred in predictions]\n",
    "\n",
    "# 성능을 평가합니다.\n",
    "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
