{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_a9QvUFVCUR"
   },
   "source": [
    "<h1>2장 토큰과 임베딩</h1>\n",
    "<i>LLM 구축의 핵심적인 부분인 토큰과 임베딩을 살펴 봅니다.</i>\n",
    "\n",
    "\n",
    "<a href=\"https://github.com/rickiepark/handson-llm\"><img src=\"https://img.shields.io/badge/GitHub%20Repository-black?logo=github\"></a>\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rickiepark/handson-llm/blob/main/chapter02.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "이 노트북은 <[핸즈온 LLM](https://tensorflow.blog/handson-llm/)> 책 2장의 코드를 담고 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "<a href=\"https://tensorflow.blog/handson-llm/\">\n",
    "<img src=\"https://tensorflow.blog/wp-content/uploads/2025/05/ed95b8eca688ec98a8_llm.jpg\" width=\"350\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCS9cqiZvs-x"
   },
   "source": [
    "---\n",
    "\n",
    "💡 **NOTE**: 이 노트북의 코드를 실행하려면 GPU를 사용하는 것이 좋습니다. 구글 코랩에서는 **런타임 > 런타임 유형 변경 > 하드웨어 가속기 > T4 GPU**를 선택하세요.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Z1qf7ir_O8k",
    "outputId": "acc56054-a738-4aeb-ca08-30c16ef73d4c"
   },
   "source": [
    "# Phi-3 모델과 호환성 때문에 transformers 4.48.3 버전을 사용합니다.\n",
    "!pip install transformers==4.48.3"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# 깃허브에서 위젯 상태 오류를 피하기 위해 진행 표시줄을 나타내지 않도록 설정합니다.\n",
    "from transformers.utils import logging\n",
    "\n",
    "logging.disable_progress_bar()"
   ],
   "metadata": {
    "id": "BKozl7tQzNjm"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQHfpqT_t9-K"
   },
   "source": [
    "# LLM 다운로드하고 실행하기\n",
    "\n",
    "빠른 추론을 위해 GPU에 모델을 로드합니다. 모델과 토크나이저를 개별적으로 살펴 보기 위해 따로따로 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jjU8NBHnwA4j",
    "outputId": "f1ced76b-e2b0-4f39-f4ce-f869cc865adb"
   },
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# 모델과 토크나이저를 로드합니다.\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_iVl5yePuq3B",
    "outputId": "f3d2a28b-5c11-4a86-d4a4-3e09f1a84b94"
   },
   "source": [
    "prompt = \"Write an email apologizing to Sarah for the tragic gardening mishap. Explain how it happened.<|assistant|>\"\n",
    "\n",
    "# 입력 프롬프트를 토큰으로 나눕니다.\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "\n",
    "# 텍스트를 생성합니다.\n",
    "generation_output = model.generate(\n",
    "  input_ids=input_ids,\n",
    "  max_new_tokens=20\n",
    ")\n",
    "\n",
    "# 출력을 프린트합니다.\n",
    "print(tokenizer.decode(generation_output[0]))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JmzgbbdKuvHt",
    "outputId": "45e0bf72-df87-4aa2-a6a9-51b0df82fa2e"
   },
   "source": [
    "print(input_ids)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W4vsjbxwu1K1",
    "outputId": "7450b5c1-42bd-4afa-bd2b-87458e16528b"
   },
   "source": [
    "for id in input_ids[0]:\n",
    "   print(tokenizer.decode(id))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A9wRZ3J3u4z1",
    "outputId": "51016bc5-e33b-49d5-d8cd-cbbfba57622a"
   },
   "source": [
    "generation_output"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7QlHLof3u8A3",
    "outputId": "c05be5aa-7b33-47a3-ec66-202b64fa03f0"
   },
   "source": [
    "print(tokenizer.decode(3323))\n",
    "print(tokenizer.decode(622))\n",
    "print(tokenizer.decode([3323, 622]))\n",
    "print(tokenizer.decode(29901))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9nRducW48bd"
   },
   "source": [
    "# 훈련된 LLM 토큰나이저 비교하기\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7W0xFIVo5A0S"
   },
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "colors_list = [\n",
    "    '102;194;165', '252;141;98', '141;160;203',\n",
    "    '231;138;195', '166;216;84', '255;217;47'\n",
    "]\n",
    "\n",
    "def show_tokens(sentence, tokenizer_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    token_ids = tokenizer(sentence).input_ids\n",
    "    for idx, t in enumerate(token_ids):\n",
    "        # 텍스트를 인코딩한 후 다시 디코딩했을 때 원본 텍스트와 동일해지려면\n",
    "        # clean_up_tokenization_spaces를 False로 지정해야 합니다.\n",
    "        # 현재 이 매개변수의 기본값은 None(True에 해당)이며\n",
    "        # transformers 4.45에서 True로 바뀔 예정입니다.\n",
    "        # https://github.com/huggingface/transformers/issues/31884\n",
    "        print(\n",
    "            f'\\x1b[0;30;48;2;{colors_list[idx % len(colors_list)]}m' +\n",
    "            tokenizer.decode(t, clean_up_tokenization_spaces=False) +\n",
    "            '\\x1b[0m',\n",
    "            end=' '\n",
    "        )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Gcc3JjwX5DK-"
   },
   "source": [
    "text = \"\"\"\n",
    "English and CAPITALIZATION\n",
    "🎵 鸟\n",
    "show_tokens False None elif == >= else: two tabs:\"\t\t\" four spaces:\"    \"\n",
    "12.0*50=600\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fCDGSXP75Hv-",
    "outputId": "399960b3-0455-43fa-e010-6b59ca089579"
   },
   "source": [
    "show_tokens(text, \"bert-base-uncased\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Ay_NX3K5HyP",
    "outputId": "a8cd4d88-6714-4596-8448-cb1bffd284d6"
   },
   "source": [
    "show_tokens(text, \"bert-base-cased\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K_k5QduY5H0u",
    "outputId": "8950be19-52aa-478f-e998-ad45d160ff7b"
   },
   "source": [
    "show_tokens(text, \"gpt2\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EJn5nf3c5H2_",
    "outputId": "adb547b0-3d3e-4e43-e881-a6c82919543b"
   },
   "source": [
    "show_tokens(text, \"google/flan-t5-small\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ymhAsTg5H5e",
    "outputId": "911067f3-7441-45a1-de0f-5ddd2f83ba32"
   },
   "source": [
    "# 공식 토크나이저는 `tiktoken`이지만 허깅 페이스 플랫폼에 동일한 토크나이저가 있습니다.\n",
    "show_tokens(text, \"Xenova/gpt-4\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_vAyeTy5H7_",
    "outputId": "3ccbed98-3cf9-48b5-e6e5-f6c10179576d"
   },
   "source": [
    "show_tokens(text, \"bigcode/starcoder2-15b\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KeWcUdxY6I3u",
    "outputId": "50397a03-b4fe-4907-fdd9-166f90d56d5a"
   },
   "source": [
    "show_tokens(text, \"facebook/galactica-1.3b\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "__QNj2Cohzz2",
    "outputId": "ebbda65b-814a-4d21-e0c4-9864859d4dad"
   },
   "source": [
    "show_tokens(text, \"microsoft/Phi-3-mini-4k-instruct\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Tu7OY4HvBEm"
   },
   "source": [
    "# (BERT와 같은) 언어 모델로 문맥을 고려한 단어 임베딩 만들기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nsjz-VsYu9bB",
    "outputId": "aa5084cf-81d8-4810-991c-cda8b90acba8"
   },
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# 토크나이저를 로드합니다.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n",
    "\n",
    "# 언어 모델을 로드합니다.\n",
    "model = AutoModel.from_pretrained(\"microsoft/deberta-v3-xsmall\")\n",
    "\n",
    "# 문장을 토큰으로 나눕니다.\n",
    "tokens = tokenizer('Hello world', return_tensors='pt')\n",
    "\n",
    "# 토큰을 처리합니다.\n",
    "output = model(**tokens)[0]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lQly_KcbvDce",
    "outputId": "02e677b3-ecda-4c75-d038-c6ae9c6c0e7d"
   },
   "source": [
    "output.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8GcRrpPV0kVj",
    "outputId": "4f144950-f8f3-4661-dc33-34f10c36e14f"
   },
   "source": [
    "for token in tokens['input_ids'][0]:\n",
    "    print(tokenizer.decode(token))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8oHVC7B0lkk",
    "outputId": "0ec63ba7-af30-47b1-d84f-c62e4f011d66"
   },
   "source": [
    "output"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DdEDuLWa0r4L"
   },
   "source": [
    "# 텍스트 임베딩 (문장과 전체 문서)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TQHWioIc0pQ8"
   },
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 모델을 로드합니다.\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# 텍스트를 텍스트 임베딩으로 변환합니다.\n",
    "vector = model.encode(\"Best movie ever!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PDwfmBiC0uER",
    "outputId": "4941073f-00a5-4e62-a58e-96911a505200"
   },
   "source": [
    "vector.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnuGRjo80yKj"
   },
   "source": [
    "# LLM 밖의 단어 임베딩\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 754
    },
    "id": "NaKFlTXjGkU0",
    "outputId": "36754edd-c27e-49a7-a851-5e745e83b401"
   },
   "source": [
    "# gensim을 설치합니다. 설치 후 코랩 런타임 세션을 다시 시작해 주세요.\n",
    "!pip install gensim"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKgNdnwe0vfK",
    "outputId": "7a65bbe7-fa77-441a-f682-7a540ebab6b2"
   },
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# 임베딩을 다운로드합니다 (66MB, glove, 위키백과에서 훈련됨, 벡터 크기: 50)\n",
    "# \"word2vec-google-news-300\"도 선택 가능합니다.\n",
    "# 더 자세한 옵션은 https://github.com/RaRe-Technologies/gensim-data 을 참고하세요.\n",
    "model = api.load(\"glove-wiki-gigaword-50\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u_vj5NVn01aD",
    "outputId": "643a814e-1f9a-4285-aa82-4206d4267f73"
   },
   "source": [
    "model.most_similar([model['king']], topn=11)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMSgyKKS4xUx"
   },
   "source": [
    "# 임베딩으로 노래 추천하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3dJdWzT67nDL"
   },
   "source": [
    "import pandas as pd\n",
    "from urllib import request\n",
    "\n",
    "# 재생목록 데이터셋 파일을 가져옵니다.\n",
    "data = request.urlopen('https://storage.googleapis.com/maps-premium/dataset/yes_complete/train.txt')\n",
    "\n",
    "# 재생목록 파일을 파싱합니다. 처음 두 줄은 메타데이터만 담고 있으므로 건너뜁니다.\n",
    "lines = data.read().decode(\"utf-8\").split('\\n')[2:]\n",
    "\n",
    "# 하나의 노래만 있는 재생목록은 삭제합니다.\n",
    "playlists = [s.rstrip().split() for s in lines if len(s.split()) > 1]\n",
    "\n",
    "# 노래의 메타데이터를 로드합니다.\n",
    "songs_file = request.urlopen('https://storage.googleapis.com/maps-premium/dataset/yes_complete/song_hash.txt')\n",
    "songs_file = songs_file.read().decode(\"utf-8\").split('\\n')\n",
    "songs = [s.rstrip().split('\\t') for s in songs_file]\n",
    "songs_df = pd.DataFrame(data=songs, columns = ['id', 'title', 'artist'])\n",
    "songs_df = songs_df.set_index('id')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q3zirG-lo3H8",
    "outputId": "e4130a27-b9a0-447a-c681-9914d8b759f1"
   },
   "source": [
    "print('재생목록 #1:\\n ', playlists[0], '\\n')\n",
    "print('재생목록 #2:\\n ', playlists[1])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EaUz3E0P7sJs"
   },
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Word2Vec 모델을 훈련합니다.\n",
    "model = Word2Vec(\n",
    "    playlists, vector_size=32, window=20, negative=50, min_count=1, workers=4\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9EFGWesO8rOJ",
    "outputId": "3c851570-224a-4e25-b48a-1d3fcdd136a3"
   },
   "source": [
    "song_id = 2172\n",
    "\n",
    "# 노래 ID 2172와 비슷한 노래를 찾으라고 모델에게 요청합니다.\n",
    "model.wv.most_similar(positive=str(song_id))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AMiY6isXqKk4",
    "outputId": "a3cd00bc-5ba9-4879-d7e0-d447f2295496"
   },
   "source": [
    "print(songs_df.iloc[2172])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "id": "aOzWENxr2Fl3",
    "outputId": "83abf695-31a7-4b63-9e45-8cac3128bf79"
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "def print_recommendations(song_id):\n",
    "    similar_songs = np.array(\n",
    "        model.wv.most_similar(positive=str(song_id),topn=5)\n",
    "    )[:,0]\n",
    "    return  songs_df.iloc[similar_songs]\n",
    "\n",
    "# 추천 노래 출력\n",
    "print_recommendations(2172)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "id": "xqrzQQ-m1EJ5",
    "outputId": "2b8f895c-24c4-4d99-96c0-c8c74ced12e8"
   },
   "source": [
    "print_recommendations(2172)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "id": "TIHiN62g1NMi",
    "outputId": "b26c3a79-76ef-45a1-8813-ec59b7e7d7b4"
   },
   "source": [
    "print_recommendations(842)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
