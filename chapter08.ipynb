{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_A2SZPmbD4Pk"
   },
   "source": [
    "<h1>8ì¥ ì‹œë§¨í‹± ê²€ìƒ‰ê³¼ RAG</h1>\n",
    "<i>LLMì˜ í•µì‹¬ ìš”ì†Œì¸ ê²€ìƒ‰ì„ ì‚´í´ ë´…ë‹ˆë‹¤.</i>\n",
    "\n",
    "<a href=\"https://github.com/rickiepark/handson-llm\"><img src=\"https://img.shields.io/badge/GitHub%20Repository-black?logo=github\"></a>\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rickiepark/handson-llm/blob/main/chapter08.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ <[í•¸ì¦ˆì˜¨ LLM](https://tensorflow.blog/handson-llm/)> ì±… 8ì¥ì˜ ì½”ë“œë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "<a href=\"https://tensorflow.blog/handson-llm/\">\n",
    "<img src=\"https://tensorflow.blog/wp-content/uploads/2025/05/ed95b8eca688ec98a8_llm.jpg\" width=\"350\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1HLGL7ihy1E"
   },
   "source": [
    "### [ì„ íƒì‚¬í•­] - <img src=\"https://colab.google/static/images/icons/colab.png\" width=100>ì—ì„œ íŒ¨í‚¤ì§€ ì„ íƒí•˜ê¸°\n",
    "\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì„ êµ¬ê¸€ ì½”ë©ì—ì„œ ì‹¤í–‰í•œë‹¤ë©´ ë‹¤ìŒ ì½”ë“œ ì…€ì„ ì‹¤í–‰í•˜ì—¬ ì´ ë…¸íŠ¸ë¶ì—ì„œ í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼  ì„¤ì¹˜í•˜ì„¸ìš”.\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ’¡ **NOTE**: ì´ ë…¸íŠ¸ë¶ì˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë ¤ë©´ GPUë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. êµ¬ê¸€ ì½”ë©ì—ì„œëŠ” **ëŸ°íƒ€ì„ > ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ > í•˜ë“œì›¨ì–´ ê°€ì†ê¸° > T4 GPU**ë¥¼ ì„ íƒí•˜ì„¸ìš”.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ê¹ƒí—ˆë¸Œì—ì„œ ìœ„ì ¯ ìƒíƒœ ì˜¤ë¥˜ë¥¼ í”¼í•˜ê¸° ìœ„í•´ ì§„í–‰ í‘œì‹œì¤„ì„ ë‚˜íƒ€ë‚´ì§€ ì•Šë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "import os\n",
    "import tqdm\n",
    "from transformers.utils import logging\n",
    "\n",
    "# tqdm ë¹„í™œì„±í™”\n",
    "# tqdm.tqdm = lambda *args, **kwargs: iter([])\n",
    "# tqdm.auto.tqdm = lambda *args, **kwargs: iter([])\n",
    "# tqdm.notebook.tqdm = lambda *args, **kwargs: iter([])\n",
    "os.environ[\"DISABLE_TQDM\"] = \"1\"\n",
    "\n",
    "logging.disable_progress_bar()"
   ],
   "metadata": {
    "id": "il-RhVV7-kbo"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zSImFYZAhy1E"
   },
   "source": [
    "%%capture\n",
    "!pip install cohere faiss-cpu rank_bm25 langchain-community\n",
    "\n",
    "# ì‚¬ìš©í•˜ëŠ” íŒŒì´ì¬ê³¼ CUDA ë²„ì „ì— ë§ëŠ” llama-cpp-python íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”.\n",
    "# í˜„ì¬ ì½”ë©ì˜ íŒŒì´ì¬ ë²„ì „ì€ 3.11ì´ë©° CUDA ë²„ì „ì€ 12.4ì…ë‹ˆë‹¤.\n",
    "!pip install https://github.com/abetlen/llama-cpp-python/releases/download/v0.3.4-cu124/llama_cpp_python-0.3.4-cp311-cp311-linux_x86_64.whl"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ye0HbBr3EV0P"
   },
   "source": [
    "## ë°€ì§‘ ê²€ìƒ‰ ì˜ˆì œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Svgdo3y3F741"
   },
   "source": [
    "### 1. í…ìŠ¤íŠ¸ ë¬¸ì„œ ë¶„í• í•˜ê¸°\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uOFFg7YWFoaf"
   },
   "source": [
    "import cohere\n",
    "\n",
    "# ì½”íˆì–´ì˜ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n",
    "api_key = 'hrnLgkfhcwNuYseUyoUP1D2DO6lCSxSkb2jNyC14'\n",
    "\n",
    "# ì½”íˆì–´ í´ë¼ì´ì–¸íŠ¸ë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
    "co = cohere.Client(api_key)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_Dcq1j_xFxIr"
   },
   "source": [
    "text = \"\"\"\n",
    "Interstellar is a 2014 epic science fiction film co-written, directed, and produced by Christopher Nolan.\n",
    "It stars Matthew McConaughey, Anne Hathaway, Jessica Chastain, Bill Irwin, Ellen Burstyn, Matt Damon, and Michael Caine.\n",
    "Set in a dystopian future where humanity is struggling to survive, the film follows a group of astronauts who travel through a wormhole near Saturn in search of a new home for mankind.\n",
    "\n",
    "Brothers Christopher and Jonathan Nolan wrote the screenplay, which had its origins in a script Jonathan developed in 2007.\n",
    "Caltech theoretical physicist and 2017 Nobel laureate in Physics[4] Kip Thorne was an executive producer, acted as a scientific consultant, and wrote a tie-in book, The Science of Interstellar.\n",
    "Cinematographer Hoyte van Hoytema shot it on 35 mm movie film in the Panavision anamorphic format and IMAX 70 mm.\n",
    "Principal photography began in late 2013 and took place in Alberta, Iceland, and Los Angeles.\n",
    "Interstellar uses extensive practical and miniature effects and the company Double Negative created additional digital effects.\n",
    "\n",
    "Interstellar premiered on October 26, 2014, in Los Angeles.\n",
    "In the United States, it was first released on film stock, expanding to venues using digital projectors.\n",
    "The film had a worldwide gross over $677 million (and $773 million with subsequent re-releases), making it the tenth-highest grossing film of 2014.\n",
    "It received acclaim for its performances, direction, screenplay, musical score, visual effects, ambition, themes, and emotional weight.\n",
    "It has also received praise from many astronomers for its scientific accuracy and portrayal of theoretical astrophysics. Since its premiere, Interstellar gained a cult following,[5] and now is regarded by many sci-fi experts as one of the best science-fiction films of all time.\n",
    "Interstellar was nominated for five awards at the 87th Academy Awards, winning Best Visual Effects, and received numerous other accolades\"\"\"\n",
    "\n",
    "# ë¬¸ì¥ì„ ë‚˜ëˆ„ì–´ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“­ë‹ˆë‹¤.\n",
    "texts = text.split('.')\n",
    "\n",
    "# ê³µë°±ê³¼ ì¤„ë°”ê¿ˆ ë¬¸ìë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.\n",
    "texts = [t.strip(' \\n') for t in texts]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krDDOpcZF5qo"
   },
   "source": [
    "### 2. ë¬¸ì¥ì„ ì„ë² ë”©í•˜ê¸°\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xooetZg0Fz4K",
    "outputId": "2967278a-dcd9-4d86-e50e-f81a6070cc2b"
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "# ì„ë² ë”©ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "response = co.embed(\n",
    "  texts=texts,\n",
    "  input_type=\"search_document\",\n",
    ").embeddings\n",
    "\n",
    "embeds = np.array(response)\n",
    "print(embeds.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLVdFg1PF4GG"
   },
   "source": [
    "### 3. ê²€ìƒ‰ ì¸ë±ìŠ¤ êµ¬ì¶•í•˜ê¸°\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JyqzN2-JF24N"
   },
   "source": [
    "import faiss\n",
    "\n",
    "dim = embeds.shape[1]\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(np.float32(embeds))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6qRFo8dGGrJ"
   },
   "source": [
    "### 4. ì¸ë±ìŠ¤ ê²€ìƒ‰í•˜ê¸°\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "o83pxM5sGHxp"
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "def search(query, number_of_results=3):\n",
    "\n",
    "  # 1. ì¿¼ë¦¬ì˜ ì„ë² ë”©ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "  query_embed = co.embed(texts=[query],\n",
    "                input_type=\"search_query\",).embeddings[0]\n",
    "\n",
    "  # 2. ìµœê·¼ì ‘ ì´ì›ƒì„ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "  distances, similar_item_ids = index.search(np.float32([query_embed]),\n",
    "                                             number_of_results)\n",
    "\n",
    "  # 3. ë°ì´í„°í”„ë ˆì„ì„ ì‚¬ìš©í•´ ì¶œë ¥ì„ ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
    "  texts_np = np.array(texts) # ì¸ë±ì‹±ì„ ì‰½ê²Œ í•˜ê¸° ìœ„í•´ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë„˜íŒŒì´ ë°°ì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "  results = pd.DataFrame(data={'í…ìŠ¤íŠ¸': texts_np[similar_item_ids[0]],\n",
    "                               'ê±°ë¦¬': distances[0]})\n",
    "\n",
    "  # 4. ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "  print(f\"ì¿¼ë¦¬:'{query}'\\nìµœê·¼ì ‘ ì´ì›ƒ:\")\n",
    "  return results"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 186
    },
    "id": "Rq_2knm_GLgR",
    "outputId": "47274550-f9c6-43f9-b8be-ca7c351b3e7e"
   },
   "source": [
    "query = \"how precise was the science\"\n",
    "results = search(query)\n",
    "results"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EkkDh12ZGRhY"
   },
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "import string\n",
    "\n",
    "def bm25_tokenizer(text):\n",
    "    tokenized_doc = []\n",
    "    for token in text.lower().split():\n",
    "        token = token.strip(string.punctuation)\n",
    "\n",
    "        if len(token) > 0 and token not in _stop_words.ENGLISH_STOP_WORDS:\n",
    "            tokenized_doc.append(token)\n",
    "    return tokenized_doc"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cHl8HnvgGXHG",
    "outputId": "00f70f10-5070-470f-8f84-a1962d8f546f"
   },
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tokenized_corpus = []\n",
    "for passage in tqdm(texts):\n",
    "    tokenized_corpus.append(bm25_tokenizer(passage))\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZlyGXye4GRj0"
   },
   "source": [
    "def keyword_search(query, top_k=3, num_candidates=15):\n",
    "    print(\"ì…ë ¥ ì§ˆë¬¸:\", query)\n",
    "\n",
    "    ##### BM25 ê²€ìƒ‰ (ì–´íœ˜ ê²€ìƒ‰) #####\n",
    "    bm25_scores = bm25.get_scores(bm25_tokenizer(query))\n",
    "    top_n = np.argpartition(bm25_scores, -num_candidates)[-num_candidates:]\n",
    "    bm25_hits = [{'corpus_id': idx, 'score': bm25_scores[idx]} for idx in top_n]\n",
    "    bm25_hits = sorted(bm25_hits, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "    print(f\"íƒ‘-3 ì–´íœ˜ ê²€ìƒ‰ (BM25) ê²°ê³¼\")\n",
    "    for hit in bm25_hits[0:top_k]:\n",
    "        print(\"\\t{:.3f}\\t{}\".format(hit['score'], texts[hit['corpus_id']].replace(\"\\n\", \" \")))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jV-V_mhRGRmS",
    "outputId": "3f2ad2df-eba2-4a21-aecc-6c0eb303819d"
   },
   "source": [
    "keyword_search(query = \"how precise was the science\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehyhfd7NG5kw"
   },
   "source": [
    "### ë°€ì§‘ ê²€ìƒ‰ì˜ ë‹¨ì \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 186
    },
    "id": "NxYwEfYRGpNe",
    "outputId": "64173232-8f28-4765-887a-563bdd828e14"
   },
   "source": [
    "query = \"What is the mass of the moon?\"\n",
    "results = search(query)\n",
    "results"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_RalLmuG0jw"
   },
   "source": [
    "## ë¦¬ë­í‚¹ ì˜ˆì œ\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HulOxkW_Focv",
    "outputId": "c63fc2f5-1b7f-416f-c185-21870b5e7b1c"
   },
   "source": [
    "query = \"how precise was the science\"\n",
    "results = co.rerank(query=query, documents=texts, top_n=3, return_documents=True)\n",
    "results.results"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SUrmMW8LFofP",
    "outputId": "f31ca01d-c31b-4abd-8363-3fba9e04c6b9"
   },
   "source": [
    "for idx, result in enumerate(results.results):\n",
    "    print(idx, result.relevance_score , result.document.text)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rqYJaq2CFohv"
   },
   "source": [
    "def keyword_and_reranking_search(query, top_k=3, num_candidates=10):\n",
    "    print(\"ì…ë ¥ ì§ˆë¬¸:\", query)\n",
    "\n",
    "    ##### BM25 ê²€ìƒ‰ (ì–´íœ˜ ê²€ìƒ‰) #####\n",
    "    bm25_scores = bm25.get_scores(bm25_tokenizer(query))\n",
    "    top_n = np.argpartition(bm25_scores, -num_candidates)[-num_candidates:]\n",
    "    bm25_hits = [{'corpus_id': idx, 'score': bm25_scores[idx]} for idx in top_n]\n",
    "    bm25_hits = sorted(bm25_hits, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "    print(f\"íƒ‘-3 ì–´íœ˜ ê²€ìƒ‰ (BM25) ê²°ê³¼\")\n",
    "    for hit in bm25_hits[0:top_k]:\n",
    "        print(\"\\t{:.3f}\\t{}\".format(hit['score'], texts[hit['corpus_id']].replace(\"\\n\", \" \")))\n",
    "\n",
    "    # ë¦¬ë­í‚¹ ì¶”ê°€\n",
    "    docs = [texts[hit['corpus_id']] for hit in bm25_hits]\n",
    "\n",
    "    print(f\"\\në¦¬ë­í‚¹ìœ¼ë¡œ ì–»ì€ íƒ‘-3 ê²°ê³¼ ({len(bm25_hits)}ê°œì˜ BM25 ê²°ê³¼ë¥¼ ì¬ì¡°ì •í•¨)\")\n",
    "    results = co.rerank(query=query, documents=docs, top_n=top_k, return_documents=True)\n",
    "    for hit in results.results:\n",
    "        print(\"\\t{:.3f}\\t{}\".format(hit.relevance_score, hit.document.text.replace(\"\\n\", \" \")))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9FITOXqkHONy",
    "outputId": "6bd210f4-0355-46c9-9753-b448fbd798e7"
   },
   "source": [
    "keyword_and_reranking_search(query = \"how precise was the science\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugdnTs_VHV25"
   },
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-iqKQ7F0HZh-"
   },
   "source": [
    "### ì˜ˆ: LLM APIë¥¼ ì‚¬ìš©í•œ ê·¼ê±° ê¸°ë°˜ ìƒì„±\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VeHX0D8DHaim",
    "outputId": "98c0abc2-0ed0-4b01-99d4-2b10eed58fdd"
   },
   "source": [
    "query = \"income generated\"\n",
    "\n",
    "# 1- ê²€ìƒ‰\n",
    "# ì—¬ê¸°ì„œëŠ” ì„ë² ë”© ê²€ìƒ‰ì„ ì‚¬ìš©í•˜ì§€ë§Œ í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ì´ ì´ìƒì ì…ë‹ˆë‹¤.\n",
    "results = search(query)\n",
    "\n",
    "# 2- ê·¼ê±° ê¸°ë°˜ ìƒì„±\n",
    "docs_dict = [{'text': text} for text in results['í…ìŠ¤íŠ¸']]\n",
    "response = co.chat(\n",
    "    message = query,\n",
    "    documents=docs_dict\n",
    ")\n",
    "\n",
    "print(response.text)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E9YmHEOHHpUW",
    "outputId": "fe1e26e7-5ade-426e-883f-f3136ec387f9"
   },
   "source": [
    "response"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YLwaGXM2Hg7b",
    "outputId": "3bf9e8b2-1d92-4ae9-b43b-edb42618c8c7"
   },
   "source": [
    "response.citations"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_25ztzEHuWX"
   },
   "source": [
    "### ì˜ˆ: ë¡œì»¬ ëª¨ë¸ì„ ì‚¬ìš©í•œ RAG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNZ5gUoWIYhp"
   },
   "source": [
    "#### ìƒì„± ëª¨ë¸ ë¡œë“œí•˜ê¸°\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E4LNwOWTHvOv",
    "outputId": "e4a8edca-27ac-444b-b94e-98f02b1a69e3"
   },
   "source": [
    "!wget https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2Qgnc5OHvRQ",
    "outputId": "af19e761-5b21-46ac-f3b9-ab8f910f7a80"
   },
   "source": [
    "from langchain import LlamaCpp\n",
    "\n",
    "# ì—¬ëŸ¬ë¶„ì˜ ì»´í“¨í„°ì— ë‹¤ìš´ë¡œë“œí•œ ëª¨ë¸ì˜ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”!\n",
    "llm = LlamaCpp(\n",
    "    model_path=\"Phi-3-mini-4k-instruct-q4.gguf\",\n",
    "    n_gpu_layers=-1,\n",
    "    max_tokens=500,\n",
    "    n_ctx=4096,\n",
    "    seed=42,\n",
    "    verbose=False\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7ahQtlvIZjS"
   },
   "source": [
    "#### ì„ë² ë”© ëª¨ë¸ ë¡œë“œí•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ODkBMgsIIddp",
    "outputId": "a0c92b2d-dc54-4c4b-ebaa-1b657907f92e"
   },
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# í…ìŠ¤íŠ¸ë¥¼ ìˆ˜ì¹˜ í‘œí˜„ìœ¼ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•œ ì„ë² ë”© ëª¨ë¸\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name='BAAI/bge-small-en-v1.5'\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgPua3jsIgmW"
   },
   "source": [
    "#### ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶•"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NV57LOf8IjM-"
   },
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# ë¡œì»¬ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
    "db = FAISS.from_texts(texts, embedding_model)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P06UYeIVIk1e"
   },
   "source": [
    "#### RAG í”„ë¡¬í”„íŠ¸\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "F_3nTc69InwO"
   },
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "template = \"\"\"<|user|>\n",
    "Relevant information:\n",
    "{context}\n",
    "\n",
    "Provide a concise answer the following question using the relevant information provided above:\n",
    "{question}<|end|>\n",
    "<|assistant|>\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# RAG íŒŒì´í”„ë¼ì¸\n",
    "rag = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type='stuff',\n",
    "    retriever=db.as_retriever(),\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": prompt\n",
    "    },\n",
    "    verbose=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x2p2pJPfIp16",
    "outputId": "4a163a5c-773b-403e-9d08-db6c16130463"
   },
   "source": [
    "rag.invoke('Income generated')"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
